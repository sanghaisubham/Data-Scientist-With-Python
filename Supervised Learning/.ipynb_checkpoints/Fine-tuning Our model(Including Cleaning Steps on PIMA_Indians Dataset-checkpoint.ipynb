{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working on PIMA_Indians Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we evaluated the performance of our k-NN classifier based on its accuracy. However, accuracy is not always an informative metric. Now we  will dive more deeply into evaluating the performance of binary classifiers by computing a confusion matrix and generating a classification report. \n",
    "\n",
    "The classification report consisted of three rows, and an additional support column. The support gives the number of samples of the true response that lie in that class.The precision, recall, and f1-score columns, then, gave the respective metrics for that particular class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "column_names=['pregnancies', 'glucose', 'diastolic', 'triceps', 'insulin', 'bmi','dpf', 'age', 'diabetes']\n",
    "df=pd.read_csv('PIMA_Indians.csv',names = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>triceps</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>dpf</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>139</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>166</td>\n",
       "      <td>72</td>\n",
       "      <td>19</td>\n",
       "      <td>175</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>84</td>\n",
       "      <td>47</td>\n",
       "      <td>230</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>83</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>88</td>\n",
       "      <td>41</td>\n",
       "      <td>235</td>\n",
       "      <td>39.3</td>\n",
       "      <td>0.704</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.4</td>\n",
       "      <td>0.388</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>196</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.451</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9</td>\n",
       "      <td>119</td>\n",
       "      <td>80</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.263</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11</td>\n",
       "      <td>143</td>\n",
       "      <td>94</td>\n",
       "      <td>33</td>\n",
       "      <td>146</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>125</td>\n",
       "      <td>70</td>\n",
       "      <td>26</td>\n",
       "      <td>115</td>\n",
       "      <td>31.1</td>\n",
       "      <td>0.205</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>147</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.4</td>\n",
       "      <td>0.257</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>15</td>\n",
       "      <td>140</td>\n",
       "      <td>23.2</td>\n",
       "      <td>0.487</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13</td>\n",
       "      <td>145</td>\n",
       "      <td>82</td>\n",
       "      <td>19</td>\n",
       "      <td>110</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>117</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.1</td>\n",
       "      <td>0.337</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "      <td>160</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.453</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0.293</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>11</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>37</td>\n",
       "      <td>150</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.785</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>44</td>\n",
       "      <td>20</td>\n",
       "      <td>94</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.400</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>58</td>\n",
       "      <td>18</td>\n",
       "      <td>116</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.219</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>9</td>\n",
       "      <td>140</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.734</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>13</td>\n",
       "      <td>153</td>\n",
       "      <td>88</td>\n",
       "      <td>37</td>\n",
       "      <td>140</td>\n",
       "      <td>40.6</td>\n",
       "      <td>1.174</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>33</td>\n",
       "      <td>105</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>94</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>49.3</td>\n",
       "      <td>0.358</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>74</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "      <td>46.3</td>\n",
       "      <td>1.096</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>3</td>\n",
       "      <td>187</td>\n",
       "      <td>70</td>\n",
       "      <td>22</td>\n",
       "      <td>200</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.408</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>6</td>\n",
       "      <td>162</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.178</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>4</td>\n",
       "      <td>136</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>1.182</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>78</td>\n",
       "      <td>39</td>\n",
       "      <td>74</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.261</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>62</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.223</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>88</td>\n",
       "      <td>44</td>\n",
       "      <td>510</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.222</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>8</td>\n",
       "      <td>154</td>\n",
       "      <td>78</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.443</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>88</td>\n",
       "      <td>39</td>\n",
       "      <td>110</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1.057</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>7</td>\n",
       "      <td>137</td>\n",
       "      <td>90</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.391</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0.258</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>0.197</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>6</td>\n",
       "      <td>190</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.278</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>9</td>\n",
       "      <td>170</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>9</td>\n",
       "      <td>89</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.142</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnancies  glucose  diastolic  triceps  insulin   bmi    dpf  age  \\\n",
       "0              6      148         72       35        0  33.6  0.627   50   \n",
       "1              1       85         66       29        0  26.6  0.351   31   \n",
       "2              8      183         64        0        0  23.3  0.672   32   \n",
       "3              1       89         66       23       94  28.1  0.167   21   \n",
       "4              0      137         40       35      168  43.1  2.288   33   \n",
       "5              5      116         74        0        0  25.6  0.201   30   \n",
       "6              3       78         50       32       88  31.0  0.248   26   \n",
       "7             10      115          0        0        0  35.3  0.134   29   \n",
       "8              2      197         70       45      543  30.5  0.158   53   \n",
       "9              8      125         96        0        0   0.0  0.232   54   \n",
       "10             4      110         92        0        0  37.6  0.191   30   \n",
       "11            10      168         74        0        0  38.0  0.537   34   \n",
       "12            10      139         80        0        0  27.1  1.441   57   \n",
       "13             1      189         60       23      846  30.1  0.398   59   \n",
       "14             5      166         72       19      175  25.8  0.587   51   \n",
       "15             7      100          0        0        0  30.0  0.484   32   \n",
       "16             0      118         84       47      230  45.8  0.551   31   \n",
       "17             7      107         74        0        0  29.6  0.254   31   \n",
       "18             1      103         30       38       83  43.3  0.183   33   \n",
       "19             1      115         70       30       96  34.6  0.529   32   \n",
       "20             3      126         88       41      235  39.3  0.704   27   \n",
       "21             8       99         84        0        0  35.4  0.388   50   \n",
       "22             7      196         90        0        0  39.8  0.451   41   \n",
       "23             9      119         80       35        0  29.0  0.263   29   \n",
       "24            11      143         94       33      146  36.6  0.254   51   \n",
       "25            10      125         70       26      115  31.1  0.205   41   \n",
       "26             7      147         76        0        0  39.4  0.257   43   \n",
       "27             1       97         66       15      140  23.2  0.487   22   \n",
       "28            13      145         82       19      110  22.2  0.245   57   \n",
       "29             5      117         92        0        0  34.1  0.337   38   \n",
       "..           ...      ...        ...      ...      ...   ...    ...  ...   \n",
       "738            2       99         60       17      160  36.6  0.453   21   \n",
       "739            1      102         74        0        0  39.5  0.293   42   \n",
       "740           11      120         80       37      150  42.3  0.785   48   \n",
       "741            3      102         44       20       94  30.8  0.400   26   \n",
       "742            1      109         58       18      116  28.5  0.219   22   \n",
       "743            9      140         94        0        0  32.7  0.734   45   \n",
       "744           13      153         88       37      140  40.6  1.174   39   \n",
       "745           12      100         84       33      105  30.0  0.488   46   \n",
       "746            1      147         94       41        0  49.3  0.358   27   \n",
       "747            1       81         74       41       57  46.3  1.096   32   \n",
       "748            3      187         70       22      200  36.4  0.408   36   \n",
       "749            6      162         62        0        0  24.3  0.178   50   \n",
       "750            4      136         70        0        0  31.2  1.182   22   \n",
       "751            1      121         78       39       74  39.0  0.261   28   \n",
       "752            3      108         62       24        0  26.0  0.223   25   \n",
       "753            0      181         88       44      510  43.3  0.222   26   \n",
       "754            8      154         78       32        0  32.4  0.443   45   \n",
       "755            1      128         88       39      110  36.5  1.057   37   \n",
       "756            7      137         90       41        0  32.0  0.391   39   \n",
       "757            0      123         72        0        0  36.3  0.258   52   \n",
       "758            1      106         76        0        0  37.5  0.197   26   \n",
       "759            6      190         92        0        0  35.5  0.278   66   \n",
       "760            2       88         58       26       16  28.4  0.766   22   \n",
       "761            9      170         74       31        0  44.0  0.403   43   \n",
       "762            9       89         62        0        0  22.5  0.142   33   \n",
       "763           10      101         76       48      180  32.9  0.171   63   \n",
       "764            2      122         70       27        0  36.8  0.340   27   \n",
       "765            5      121         72       23      112  26.2  0.245   30   \n",
       "766            1      126         60        0        0  30.1  0.349   47   \n",
       "767            1       93         70       31        0  30.4  0.315   23   \n",
       "\n",
       "     diabetes  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           0  \n",
       "4           1  \n",
       "5           0  \n",
       "6           1  \n",
       "7           0  \n",
       "8           1  \n",
       "9           1  \n",
       "10          0  \n",
       "11          1  \n",
       "12          0  \n",
       "13          1  \n",
       "14          1  \n",
       "15          1  \n",
       "16          1  \n",
       "17          1  \n",
       "18          0  \n",
       "19          1  \n",
       "20          0  \n",
       "21          0  \n",
       "22          1  \n",
       "23          1  \n",
       "24          1  \n",
       "25          1  \n",
       "26          1  \n",
       "27          0  \n",
       "28          0  \n",
       "29          0  \n",
       "..        ...  \n",
       "738         0  \n",
       "739         1  \n",
       "740         1  \n",
       "741         0  \n",
       "742         0  \n",
       "743         1  \n",
       "744         0  \n",
       "745         0  \n",
       "746         1  \n",
       "747         0  \n",
       "748         1  \n",
       "749         1  \n",
       "750         1  \n",
       "751         0  \n",
       "752         0  \n",
       "753         1  \n",
       "754         1  \n",
       "755         1  \n",
       "756         0  \n",
       "757         1  \n",
       "758         0  \n",
       "759         1  \n",
       "760         0  \n",
       "761         1  \n",
       "762         0  \n",
       "763         0  \n",
       "764         0  \n",
       "765         0  \n",
       "766         1  \n",
       "767         0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define a generic function using Pandas replace function\n",
    "import numpy as np\n",
    "def coding(col, codeDict):\n",
    "  colCoded = pd.Series(col, copy=True)\n",
    "  for key, value in codeDict.items():\n",
    "    colCoded.replace(key, value, inplace=True)\n",
    "  return colCoded\n",
    " \n",
    "#Coding Columns as ? to NULL:\n",
    "df['diastolic'] = coding(df['diastolic'], {0:np.nan})\n",
    "df['triceps'] = coding(df['triceps'], {0:np.nan})\n",
    "df['insulin'] = coding(df['insulin'], {0:np.nan})\n",
    "df['glucose'] = coding(df['glucose'], {0:np.nan})\n",
    "df['bmi'] = coding(df['bmi'], {0:np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>triceps</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>dpf</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>110.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>168.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>139.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>189.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>166.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>107.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>103.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>115.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>126.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>39.3</td>\n",
       "      <td>0.704</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>99.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.4</td>\n",
       "      <td>0.388</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>196.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.451</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9</td>\n",
       "      <td>119.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.263</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11</td>\n",
       "      <td>143.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>125.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>31.1</td>\n",
       "      <td>0.205</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>147.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.4</td>\n",
       "      <td>0.257</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>0.487</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13</td>\n",
       "      <td>145.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>117.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.1</td>\n",
       "      <td>0.337</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.453</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>1</td>\n",
       "      <td>102.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0.293</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>11</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.785</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>3</td>\n",
       "      <td>102.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.400</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>1</td>\n",
       "      <td>109.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.219</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>9</td>\n",
       "      <td>140.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.734</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>13</td>\n",
       "      <td>153.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>40.6</td>\n",
       "      <td>1.174</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>12</td>\n",
       "      <td>100.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>1</td>\n",
       "      <td>147.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.3</td>\n",
       "      <td>0.358</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>46.3</td>\n",
       "      <td>1.096</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>3</td>\n",
       "      <td>187.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.408</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>6</td>\n",
       "      <td>162.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.178</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>4</td>\n",
       "      <td>136.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.2</td>\n",
       "      <td>1.182</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>1</td>\n",
       "      <td>121.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.261</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>3</td>\n",
       "      <td>108.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.223</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.222</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>8</td>\n",
       "      <td>154.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.443</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>1</td>\n",
       "      <td>128.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1.057</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>7</td>\n",
       "      <td>137.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.391</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0.258</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>1</td>\n",
       "      <td>106.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.5</td>\n",
       "      <td>0.197</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.278</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>9</td>\n",
       "      <td>170.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>9</td>\n",
       "      <td>89.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.142</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnancies  glucose  diastolic  triceps  insulin   bmi    dpf  age  \\\n",
       "0              6    148.0       72.0     35.0      NaN  33.6  0.627   50   \n",
       "1              1     85.0       66.0     29.0      NaN  26.6  0.351   31   \n",
       "2              8    183.0       64.0      NaN      NaN  23.3  0.672   32   \n",
       "3              1     89.0       66.0     23.0     94.0  28.1  0.167   21   \n",
       "4              0    137.0       40.0     35.0    168.0  43.1  2.288   33   \n",
       "5              5    116.0       74.0      NaN      NaN  25.6  0.201   30   \n",
       "6              3     78.0       50.0     32.0     88.0  31.0  0.248   26   \n",
       "7             10    115.0        NaN      NaN      NaN  35.3  0.134   29   \n",
       "8              2    197.0       70.0     45.0    543.0  30.5  0.158   53   \n",
       "9              8    125.0       96.0      NaN      NaN   NaN  0.232   54   \n",
       "10             4    110.0       92.0      NaN      NaN  37.6  0.191   30   \n",
       "11            10    168.0       74.0      NaN      NaN  38.0  0.537   34   \n",
       "12            10    139.0       80.0      NaN      NaN  27.1  1.441   57   \n",
       "13             1    189.0       60.0     23.0    846.0  30.1  0.398   59   \n",
       "14             5    166.0       72.0     19.0    175.0  25.8  0.587   51   \n",
       "15             7    100.0        NaN      NaN      NaN  30.0  0.484   32   \n",
       "16             0    118.0       84.0     47.0    230.0  45.8  0.551   31   \n",
       "17             7    107.0       74.0      NaN      NaN  29.6  0.254   31   \n",
       "18             1    103.0       30.0     38.0     83.0  43.3  0.183   33   \n",
       "19             1    115.0       70.0     30.0     96.0  34.6  0.529   32   \n",
       "20             3    126.0       88.0     41.0    235.0  39.3  0.704   27   \n",
       "21             8     99.0       84.0      NaN      NaN  35.4  0.388   50   \n",
       "22             7    196.0       90.0      NaN      NaN  39.8  0.451   41   \n",
       "23             9    119.0       80.0     35.0      NaN  29.0  0.263   29   \n",
       "24            11    143.0       94.0     33.0    146.0  36.6  0.254   51   \n",
       "25            10    125.0       70.0     26.0    115.0  31.1  0.205   41   \n",
       "26             7    147.0       76.0      NaN      NaN  39.4  0.257   43   \n",
       "27             1     97.0       66.0     15.0    140.0  23.2  0.487   22   \n",
       "28            13    145.0       82.0     19.0    110.0  22.2  0.245   57   \n",
       "29             5    117.0       92.0      NaN      NaN  34.1  0.337   38   \n",
       "..           ...      ...        ...      ...      ...   ...    ...  ...   \n",
       "738            2     99.0       60.0     17.0    160.0  36.6  0.453   21   \n",
       "739            1    102.0       74.0      NaN      NaN  39.5  0.293   42   \n",
       "740           11    120.0       80.0     37.0    150.0  42.3  0.785   48   \n",
       "741            3    102.0       44.0     20.0     94.0  30.8  0.400   26   \n",
       "742            1    109.0       58.0     18.0    116.0  28.5  0.219   22   \n",
       "743            9    140.0       94.0      NaN      NaN  32.7  0.734   45   \n",
       "744           13    153.0       88.0     37.0    140.0  40.6  1.174   39   \n",
       "745           12    100.0       84.0     33.0    105.0  30.0  0.488   46   \n",
       "746            1    147.0       94.0     41.0      NaN  49.3  0.358   27   \n",
       "747            1     81.0       74.0     41.0     57.0  46.3  1.096   32   \n",
       "748            3    187.0       70.0     22.0    200.0  36.4  0.408   36   \n",
       "749            6    162.0       62.0      NaN      NaN  24.3  0.178   50   \n",
       "750            4    136.0       70.0      NaN      NaN  31.2  1.182   22   \n",
       "751            1    121.0       78.0     39.0     74.0  39.0  0.261   28   \n",
       "752            3    108.0       62.0     24.0      NaN  26.0  0.223   25   \n",
       "753            0    181.0       88.0     44.0    510.0  43.3  0.222   26   \n",
       "754            8    154.0       78.0     32.0      NaN  32.4  0.443   45   \n",
       "755            1    128.0       88.0     39.0    110.0  36.5  1.057   37   \n",
       "756            7    137.0       90.0     41.0      NaN  32.0  0.391   39   \n",
       "757            0    123.0       72.0      NaN      NaN  36.3  0.258   52   \n",
       "758            1    106.0       76.0      NaN      NaN  37.5  0.197   26   \n",
       "759            6    190.0       92.0      NaN      NaN  35.5  0.278   66   \n",
       "760            2     88.0       58.0     26.0     16.0  28.4  0.766   22   \n",
       "761            9    170.0       74.0     31.0      NaN  44.0  0.403   43   \n",
       "762            9     89.0       62.0      NaN      NaN  22.5  0.142   33   \n",
       "763           10    101.0       76.0     48.0    180.0  32.9  0.171   63   \n",
       "764            2    122.0       70.0     27.0      NaN  36.8  0.340   27   \n",
       "765            5    121.0       72.0     23.0    112.0  26.2  0.245   30   \n",
       "766            1    126.0       60.0      NaN      NaN  30.1  0.349   47   \n",
       "767            1     93.0       70.0     31.0      NaN  30.4  0.315   23   \n",
       "\n",
       "     diabetes  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           0  \n",
       "4           1  \n",
       "5           0  \n",
       "6           1  \n",
       "7           0  \n",
       "8           1  \n",
       "9           1  \n",
       "10          0  \n",
       "11          1  \n",
       "12          0  \n",
       "13          1  \n",
       "14          1  \n",
       "15          1  \n",
       "16          1  \n",
       "17          1  \n",
       "18          0  \n",
       "19          1  \n",
       "20          0  \n",
       "21          0  \n",
       "22          1  \n",
       "23          1  \n",
       "24          1  \n",
       "25          1  \n",
       "26          1  \n",
       "27          0  \n",
       "28          0  \n",
       "29          0  \n",
       "..        ...  \n",
       "738         0  \n",
       "739         1  \n",
       "740         1  \n",
       "741         0  \n",
       "742         0  \n",
       "743         1  \n",
       "744         0  \n",
       "745         0  \n",
       "746         1  \n",
       "747         0  \n",
       "748         1  \n",
       "749         1  \n",
       "750         1  \n",
       "751         0  \n",
       "752         0  \n",
       "753         1  \n",
       "754         1  \n",
       "755         1  \n",
       "756         0  \n",
       "757         1  \n",
       "758         0  \n",
       "759         1  \n",
       "760         0  \n",
       "761         1  \n",
       "762         0  \n",
       "763         0  \n",
       "764         0  \n",
       "765         0  \n",
       "766         1  \n",
       "767         0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pregnancies    768\n",
      "glucose        763\n",
      "diastolic      733\n",
      "triceps        541\n",
      "insulin        394\n",
      "bmi            757\n",
      "dpf            768\n",
      "age            768\n",
      "diabetes       768\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.count(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "def mymean(val):\n",
    "    sum1=0\n",
    "    count1=0\n",
    "    for j in df[val]:\n",
    "           if math.isnan(j)==False:\n",
    "                sum1=sum1+j\n",
    "                count1=count1+1\n",
    "    return sum1/count1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pregnancies    768\n",
      "glucose        763\n",
      "diastolic      733\n",
      "triceps        541\n",
      "insulin        394\n",
      "bmi            757\n",
      "dpf            768\n",
      "age            768\n",
      "diabetes       768\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pregnancies    768\n",
      "glucose        768\n",
      "diastolic      768\n",
      "triceps        768\n",
      "insulin        768\n",
      "bmi            768\n",
      "dpf            768\n",
      "age            768\n",
      "diabetes       768\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Now check the #missing values:\n",
    "print(df.count(axis=0))\n",
    "print(\"\\n\\n\\n\")\n",
    "#Impute the values:\n",
    "for j in df.columns:\n",
    "    df[j].fillna(mymean(j), inplace=True)\n",
    "print(\"\\n\\n\\n\")\n",
    "#Now check the #missing values again to confirm:\n",
    "print(df.count(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "pregnancies    768 non-null int64\n",
      "glucose        768 non-null float64\n",
      "diastolic      768 non-null float64\n",
      "triceps        768 non-null float64\n",
      "insulin        768 non-null float64\n",
      "bmi            768 non-null float64\n",
      "dpf            768 non-null float64\n",
      "age            768 non-null int64\n",
      "diabetes       768 non-null int64\n",
      "dtypes: float64(6), int64(3)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>triceps</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>dpf</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>33.600000</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>29.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>26.600000</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>28.100000</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>43.100000</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>25.600000</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115.0</td>\n",
       "      <td>72.405184</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>35.300000</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>45.00000</td>\n",
       "      <td>543.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125.0</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>32.457464</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>110.0</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>37.600000</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>168.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>139.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>27.100000</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>189.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>30.100000</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>166.0</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>19.00000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>25.800000</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>72.405184</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.484</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>47.00000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>45.800000</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>107.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>29.600000</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>103.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>38.00000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>43.300000</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>115.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>34.600000</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>126.0</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>41.00000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>39.300000</td>\n",
       "      <td>0.704</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>99.0</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>35.400000</td>\n",
       "      <td>0.388</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>196.0</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>39.800000</td>\n",
       "      <td>0.451</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9</td>\n",
       "      <td>119.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.263</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11</td>\n",
       "      <td>143.0</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>33.00000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.254</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>125.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>26.00000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>31.100000</td>\n",
       "      <td>0.205</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>147.0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>39.400000</td>\n",
       "      <td>0.257</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>0.487</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13</td>\n",
       "      <td>145.0</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>19.00000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>22.200000</td>\n",
       "      <td>0.245</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>117.0</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>34.100000</td>\n",
       "      <td>0.337</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.453</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>1</td>\n",
       "      <td>102.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>0.293</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>11</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>42.300000</td>\n",
       "      <td>0.785</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>3</td>\n",
       "      <td>102.0</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>30.800000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>1</td>\n",
       "      <td>109.0</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>0.219</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>9</td>\n",
       "      <td>140.0</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>32.700000</td>\n",
       "      <td>0.734</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>13</td>\n",
       "      <td>153.0</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>40.600000</td>\n",
       "      <td>1.174</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>12</td>\n",
       "      <td>100.0</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>33.00000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.488</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>1</td>\n",
       "      <td>147.0</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>41.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>49.300000</td>\n",
       "      <td>0.358</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>41.00000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>46.300000</td>\n",
       "      <td>1.096</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>3</td>\n",
       "      <td>187.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>36.400000</td>\n",
       "      <td>0.408</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>6</td>\n",
       "      <td>162.0</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>24.300000</td>\n",
       "      <td>0.178</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>4</td>\n",
       "      <td>136.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>31.200000</td>\n",
       "      <td>1.182</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>1</td>\n",
       "      <td>121.0</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.261</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>3</td>\n",
       "      <td>108.0</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.223</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>44.00000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>43.300000</td>\n",
       "      <td>0.222</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>8</td>\n",
       "      <td>154.0</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>32.400000</td>\n",
       "      <td>0.443</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>1</td>\n",
       "      <td>128.0</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>1.057</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>7</td>\n",
       "      <td>137.0</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>41.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.391</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>36.300000</td>\n",
       "      <td>0.258</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>1</td>\n",
       "      <td>106.0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>0.197</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>0.278</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>26.00000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>28.400000</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>9</td>\n",
       "      <td>170.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>31.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.403</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>9</td>\n",
       "      <td>89.0</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.142</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101.0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>48.00000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>32.900000</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>36.800000</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121.0</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>26.200000</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>30.100000</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>31.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>30.400000</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnancies  glucose  diastolic   triceps     insulin        bmi    dpf  \\\n",
       "0              6    148.0  72.000000  35.00000  155.548223  33.600000  0.627   \n",
       "1              1     85.0  66.000000  29.00000  155.548223  26.600000  0.351   \n",
       "2              8    183.0  64.000000  29.15342  155.548223  23.300000  0.672   \n",
       "3              1     89.0  66.000000  23.00000   94.000000  28.100000  0.167   \n",
       "4              0    137.0  40.000000  35.00000  168.000000  43.100000  2.288   \n",
       "5              5    116.0  74.000000  29.15342  155.548223  25.600000  0.201   \n",
       "6              3     78.0  50.000000  32.00000   88.000000  31.000000  0.248   \n",
       "7             10    115.0  72.405184  29.15342  155.548223  35.300000  0.134   \n",
       "8              2    197.0  70.000000  45.00000  543.000000  30.500000  0.158   \n",
       "9              8    125.0  96.000000  29.15342  155.548223  32.457464  0.232   \n",
       "10             4    110.0  92.000000  29.15342  155.548223  37.600000  0.191   \n",
       "11            10    168.0  74.000000  29.15342  155.548223  38.000000  0.537   \n",
       "12            10    139.0  80.000000  29.15342  155.548223  27.100000  1.441   \n",
       "13             1    189.0  60.000000  23.00000  846.000000  30.100000  0.398   \n",
       "14             5    166.0  72.000000  19.00000  175.000000  25.800000  0.587   \n",
       "15             7    100.0  72.405184  29.15342  155.548223  30.000000  0.484   \n",
       "16             0    118.0  84.000000  47.00000  230.000000  45.800000  0.551   \n",
       "17             7    107.0  74.000000  29.15342  155.548223  29.600000  0.254   \n",
       "18             1    103.0  30.000000  38.00000   83.000000  43.300000  0.183   \n",
       "19             1    115.0  70.000000  30.00000   96.000000  34.600000  0.529   \n",
       "20             3    126.0  88.000000  41.00000  235.000000  39.300000  0.704   \n",
       "21             8     99.0  84.000000  29.15342  155.548223  35.400000  0.388   \n",
       "22             7    196.0  90.000000  29.15342  155.548223  39.800000  0.451   \n",
       "23             9    119.0  80.000000  35.00000  155.548223  29.000000  0.263   \n",
       "24            11    143.0  94.000000  33.00000  146.000000  36.600000  0.254   \n",
       "25            10    125.0  70.000000  26.00000  115.000000  31.100000  0.205   \n",
       "26             7    147.0  76.000000  29.15342  155.548223  39.400000  0.257   \n",
       "27             1     97.0  66.000000  15.00000  140.000000  23.200000  0.487   \n",
       "28            13    145.0  82.000000  19.00000  110.000000  22.200000  0.245   \n",
       "29             5    117.0  92.000000  29.15342  155.548223  34.100000  0.337   \n",
       "..           ...      ...        ...       ...         ...        ...    ...   \n",
       "738            2     99.0  60.000000  17.00000  160.000000  36.600000  0.453   \n",
       "739            1    102.0  74.000000  29.15342  155.548223  39.500000  0.293   \n",
       "740           11    120.0  80.000000  37.00000  150.000000  42.300000  0.785   \n",
       "741            3    102.0  44.000000  20.00000   94.000000  30.800000  0.400   \n",
       "742            1    109.0  58.000000  18.00000  116.000000  28.500000  0.219   \n",
       "743            9    140.0  94.000000  29.15342  155.548223  32.700000  0.734   \n",
       "744           13    153.0  88.000000  37.00000  140.000000  40.600000  1.174   \n",
       "745           12    100.0  84.000000  33.00000  105.000000  30.000000  0.488   \n",
       "746            1    147.0  94.000000  41.00000  155.548223  49.300000  0.358   \n",
       "747            1     81.0  74.000000  41.00000   57.000000  46.300000  1.096   \n",
       "748            3    187.0  70.000000  22.00000  200.000000  36.400000  0.408   \n",
       "749            6    162.0  62.000000  29.15342  155.548223  24.300000  0.178   \n",
       "750            4    136.0  70.000000  29.15342  155.548223  31.200000  1.182   \n",
       "751            1    121.0  78.000000  39.00000   74.000000  39.000000  0.261   \n",
       "752            3    108.0  62.000000  24.00000  155.548223  26.000000  0.223   \n",
       "753            0    181.0  88.000000  44.00000  510.000000  43.300000  0.222   \n",
       "754            8    154.0  78.000000  32.00000  155.548223  32.400000  0.443   \n",
       "755            1    128.0  88.000000  39.00000  110.000000  36.500000  1.057   \n",
       "756            7    137.0  90.000000  41.00000  155.548223  32.000000  0.391   \n",
       "757            0    123.0  72.000000  29.15342  155.548223  36.300000  0.258   \n",
       "758            1    106.0  76.000000  29.15342  155.548223  37.500000  0.197   \n",
       "759            6    190.0  92.000000  29.15342  155.548223  35.500000  0.278   \n",
       "760            2     88.0  58.000000  26.00000   16.000000  28.400000  0.766   \n",
       "761            9    170.0  74.000000  31.00000  155.548223  44.000000  0.403   \n",
       "762            9     89.0  62.000000  29.15342  155.548223  22.500000  0.142   \n",
       "763           10    101.0  76.000000  48.00000  180.000000  32.900000  0.171   \n",
       "764            2    122.0  70.000000  27.00000  155.548223  36.800000  0.340   \n",
       "765            5    121.0  72.000000  23.00000  112.000000  26.200000  0.245   \n",
       "766            1    126.0  60.000000  29.15342  155.548223  30.100000  0.349   \n",
       "767            1     93.0  70.000000  31.00000  155.548223  30.400000  0.315   \n",
       "\n",
       "     age  diabetes  \n",
       "0     50         1  \n",
       "1     31         0  \n",
       "2     32         1  \n",
       "3     21         0  \n",
       "4     33         1  \n",
       "5     30         0  \n",
       "6     26         1  \n",
       "7     29         0  \n",
       "8     53         1  \n",
       "9     54         1  \n",
       "10    30         0  \n",
       "11    34         1  \n",
       "12    57         0  \n",
       "13    59         1  \n",
       "14    51         1  \n",
       "15    32         1  \n",
       "16    31         1  \n",
       "17    31         1  \n",
       "18    33         0  \n",
       "19    32         1  \n",
       "20    27         0  \n",
       "21    50         0  \n",
       "22    41         1  \n",
       "23    29         1  \n",
       "24    51         1  \n",
       "25    41         1  \n",
       "26    43         1  \n",
       "27    22         0  \n",
       "28    57         0  \n",
       "29    38         0  \n",
       "..   ...       ...  \n",
       "738   21         0  \n",
       "739   42         1  \n",
       "740   48         1  \n",
       "741   26         0  \n",
       "742   22         0  \n",
       "743   45         1  \n",
       "744   39         0  \n",
       "745   46         0  \n",
       "746   27         1  \n",
       "747   32         0  \n",
       "748   36         1  \n",
       "749   50         1  \n",
       "750   22         1  \n",
       "751   28         0  \n",
       "752   25         0  \n",
       "753   26         1  \n",
       "754   45         1  \n",
       "755   37         1  \n",
       "756   39         0  \n",
       "757   52         1  \n",
       "758   26         0  \n",
       "759   66         1  \n",
       "760   22         0  \n",
       "761   43         1  \n",
       "762   33         0  \n",
       "763   63         0  \n",
       "764   27         0  \n",
       "765   30         0  \n",
       "766   47         1  \n",
       "767   23         0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'diabetes': 500, 'pregnancies': 111}\n"
     ]
    }
   ],
   "source": [
    "dictzeros={}\n",
    "for index, row in df.iterrows():\n",
    "    for j in df.columns:\n",
    "        if row[j]==0:\n",
    "            if j not in dictzeros:\n",
    "                dictzeros[j]=1\n",
    "            else:\n",
    "                dictzeros[j]=dictzeros[j]+1\n",
    "print(dictzeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll work with the PIMA Indians dataset obtained from the UCI Machine Learning Repository. The goal is to predict whether or not a given female patient will contract diabetes based on features such as BMI, age, and number of pregnancies. Therefore, it is a binary classification problem. A target value of 0 indicates that the patient does not have diabetes, while a value of 1 indicates that the patient does have diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df['diabetes'].values\n",
    "X = df.drop('diabetes', axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[167  34]\n",
      " [ 56  51]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.83      0.79       201\n",
      "          1       0.60      0.48      0.53       107\n",
      "\n",
      "avg / total       0.70      0.71      0.70       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "# Create training and test set\n",
    "X_train, X_test, y_train, y_test =train_test_split(X,y, test_size =0.4, random_state=42, stratify=y)\n",
    "\n",
    "# Instantiate a k-NN classifier: knn\n",
    "knn =KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "# Predict the labels of the test data: y_pred\n",
    "y_pred =knn.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By analyzing the confusion matrix and classification report, you can get a much better understanding of your classifier's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn makes it very easy to try different models, since the Train-Test-Split/Instantiate/Fit/Predict paradigm applies to all classifiers and regressors - which are known in scikit-learn as 'estimators'. We'll see this now for ourself as we train a logistic regression model on exactly the same data as in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[175  31]\n",
      " [ 41  61]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.85      0.83       206\n",
      "          1       0.66      0.60      0.63       102\n",
      "\n",
      "avg / total       0.76      0.77      0.76       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\n",
    "\n",
    "# Create the classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Compute and print the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know how to use logistic regression for binary classification. Logistic regression is used in a variety of machine learning applications and will become a vital part of your data science toolbox."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification reports and confusion matrices are great methods to quantitatively evaluate model performance, while ROC curves provide a way to visually evaluate models.\n",
    "\n",
    "Most classifiers in scikit-learn have a .predict_proba() method which returns the probability of a given sample being in a particular class. Having built a logistic regression model, we'll now evaluate its performance by plotting an ROC curve. In doing so, we'll make use of the .predict_proba() method and become familiar with its functionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(308, 8)\n",
      "\n",
      "\n",
      " The probabilities to belong to a Class:\n",
      "\n",
      "\n",
      "0 [ 0.56313138  0.43686862]\n",
      "1 [ 0.77890584  0.22109416]\n",
      "2 [ 0.78960305  0.21039695]\n",
      "3 [ 0.82004038  0.17995962]\n",
      "4 [ 0.61274259  0.38725741]\n",
      "5 [ 0.51479049  0.48520951]\n",
      "6 [ 0.92916762  0.07083238]\n",
      "7 [ 0.6572518  0.3427482]\n",
      "8 [ 0.44577955  0.55422045]\n",
      "9 [ 0.31779326  0.68220674]\n",
      "10 [ 0.64930813  0.35069187]\n",
      "11 [ 0.25399252  0.74600748]\n",
      "12 [ 0.39782087  0.60217913]\n",
      "13 [ 0.72242132  0.27757868]\n",
      "14 [ 0.86285569  0.13714431]\n",
      "15 [ 0.50578143  0.49421857]\n",
      "16 [ 0.82334744  0.17665256]\n",
      "17 [ 0.86404093  0.13595907]\n",
      "18 [ 0.31820403  0.68179597]\n",
      "19 [ 0.41922268  0.58077732]\n",
      "20 [ 0.73995456  0.26004544]\n",
      "21 [ 0.90033754  0.09966246]\n",
      "22 [ 0.47987088  0.52012912]\n",
      "23 [ 0.82957195  0.17042805]\n",
      "24 [ 0.44137031  0.55862969]\n",
      "25 [ 0.22271383  0.77728617]\n",
      "26 [ 0.75269551  0.24730449]\n",
      "27 [ 0.93428935  0.06571065]\n",
      "28 [ 0.76922822  0.23077178]\n",
      "29 [ 0.84376222  0.15623778]\n",
      "30 [ 0.22909517  0.77090483]\n",
      "31 [ 0.24966448  0.75033552]\n",
      "32 [ 0.23670598  0.76329402]\n",
      "33 [ 0.44016593  0.55983407]\n",
      "34 [ 0.6281449  0.3718551]\n",
      "35 [ 0.37025298  0.62974702]\n",
      "36 [ 0.12967299  0.87032701]\n",
      "37 [ 0.8429604  0.1570396]\n",
      "38 [ 0.4881281  0.5118719]\n",
      "39 [ 0.52506435  0.47493565]\n",
      "40 [ 0.84213451  0.15786549]\n",
      "41 [ 0.38755071  0.61244929]\n",
      "42 [ 0.51464719  0.48535281]\n",
      "43 [ 0.59755443  0.40244557]\n",
      "44 [ 0.95601698  0.04398302]\n",
      "45 [ 0.48851604  0.51148396]\n",
      "46 [ 0.48421423  0.51578577]\n",
      "47 [ 0.74423111  0.25576889]\n",
      "48 [ 0.64180819  0.35819181]\n",
      "49 [ 0.11302412  0.88697588]\n",
      "50 [ 0.88122843  0.11877157]\n",
      "51 [ 0.45837123  0.54162877]\n",
      "52 [ 0.21013297  0.78986703]\n",
      "53 [ 0.70583186  0.29416814]\n",
      "54 [ 0.749133  0.250867]\n",
      "55 [ 0.91836315  0.08163685]\n",
      "56 [ 0.26700547  0.73299453]\n",
      "57 [ 0.89634004  0.10365996]\n",
      "58 [ 0.6226677  0.3773323]\n",
      "59 [ 0.23580929  0.76419071]\n",
      "60 [ 0.35184617  0.64815383]\n",
      "61 [ 0.63073459  0.36926541]\n",
      "62 [ 0.71932878  0.28067122]\n",
      "63 [ 0.5769838  0.4230162]\n",
      "64 [ 0.90023989  0.09976011]\n",
      "65 [ 0.57297597  0.42702403]\n",
      "66 [ 0.88019292  0.11980708]\n",
      "67 [ 0.53725638  0.46274362]\n",
      "68 [ 0.93857175  0.06142825]\n",
      "69 [ 0.17148587  0.82851413]\n",
      "70 [ 0.24888982  0.75111018]\n",
      "71 [ 0.91369572  0.08630428]\n",
      "72 [ 0.72475648  0.27524352]\n",
      "73 [ 0.89024205  0.10975795]\n",
      "74 [ 0.81711737  0.18288263]\n",
      "75 [ 0.75387745  0.24612255]\n",
      "76 [ 0.81992261  0.18007739]\n",
      "77 [ 0.77855658  0.22144342]\n",
      "78 [ 0.77135751  0.22864249]\n",
      "79 [ 0.80040442  0.19959558]\n",
      "80 [ 0.32386195  0.67613805]\n",
      "81 [ 0.80637248  0.19362752]\n",
      "82 [ 0.88545406  0.11454594]\n",
      "83 [ 0.73844281  0.26155719]\n",
      "84 [ 0.68173554  0.31826446]\n",
      "85 [ 0.17279357  0.82720643]\n",
      "86 [ 0.24357412  0.75642588]\n",
      "87 [ 0.62687535  0.37312465]\n",
      "88 [ 0.82387242  0.17612758]\n",
      "89 [ 0.81331778  0.18668222]\n",
      "90 [ 0.86546205  0.13453795]\n",
      "91 [ 0.75565485  0.24434515]\n",
      "92 [ 0.91720242  0.08279758]\n",
      "93 [ 0.61757282  0.38242718]\n",
      "94 [ 0.34292814  0.65707186]\n",
      "95 [ 0.52817985  0.47182015]\n",
      "96 [ 0.4612386  0.5387614]\n",
      "97 [ 0.8231215  0.1768785]\n",
      "98 [ 0.22799971  0.77200029]\n",
      "99 [ 0.88472398  0.11527602]\n",
      "100 [ 0.44588986  0.55411014]\n",
      "101 [ 0.94067453  0.05932547]\n",
      "102 [ 0.36092849  0.63907151]\n",
      "103 [ 0.48736799  0.51263201]\n",
      "104 [ 0.4586817  0.5413183]\n",
      "105 [ 0.78760829  0.21239171]\n",
      "106 [ 0.62672171  0.37327829]\n",
      "107 [ 0.36245511  0.63754489]\n",
      "108 [ 0.89992295  0.10007705]\n",
      "109 [ 0.61308225  0.38691775]\n",
      "110 [ 0.80696095  0.19303905]\n",
      "111 [ 0.71054086  0.28945914]\n",
      "112 [ 0.75200905  0.24799095]\n",
      "113 [ 0.43317584  0.56682416]\n",
      "114 [ 0.7599665  0.2400335]\n",
      "115 [ 0.60414685  0.39585315]\n",
      "116 [ 0.22932692  0.77067308]\n",
      "117 [ 0.70515183  0.29484817]\n",
      "118 [ 0.87001064  0.12998936]\n",
      "119 [ 0.57407321  0.42592679]\n",
      "120 [ 0.8508968  0.1491032]\n",
      "121 [ 0.74435125  0.25564875]\n",
      "122 [ 0.73344186  0.26655814]\n",
      "123 [ 0.88467533  0.11532467]\n",
      "124 [ 0.60078882  0.39921118]\n",
      "125 [ 0.5522211  0.4477789]\n",
      "126 [ 0.61490754  0.38509246]\n",
      "127 [ 0.21829196  0.78170804]\n",
      "128 [ 0.130428  0.869572]\n",
      "129 [ 0.58305319  0.41694681]\n",
      "130 [ 0.27915564  0.72084436]\n",
      "131 [ 0.14882869  0.85117131]\n",
      "132 [ 0.80389065  0.19610935]\n",
      "133 [ 0.57382853  0.42617147]\n",
      "134 [ 0.27214872  0.72785128]\n",
      "135 [ 0.83154878  0.16845122]\n",
      "136 [ 0.81227053  0.18772947]\n",
      "137 [ 0.37481172  0.62518828]\n",
      "138 [ 0.29505712  0.70494288]\n",
      "139 [ 0.95754134  0.04245866]\n",
      "140 [ 0.83042443  0.16957557]\n",
      "141 [ 0.89131795  0.10868205]\n",
      "142 [ 0.74268386  0.25731614]\n",
      "143 [ 0.37172024  0.62827976]\n",
      "144 [ 0.78525564  0.21474436]\n",
      "145 [ 0.70086909  0.29913091]\n",
      "146 [ 0.85509208  0.14490792]\n",
      "147 [ 0.91099586  0.08900414]\n",
      "148 [ 0.6342098  0.3657902]\n",
      "149 [ 0.36004979  0.63995021]\n",
      "150 [ 0.83963645  0.16036355]\n",
      "151 [ 0.53478258  0.46521742]\n",
      "152 [ 0.58713047  0.41286953]\n",
      "153 [ 0.7869618  0.2130382]\n",
      "154 [ 0.89411023  0.10588977]\n",
      "155 [ 0.65548688  0.34451312]\n",
      "156 [ 0.50094454  0.49905546]\n",
      "157 [ 0.28980886  0.71019114]\n",
      "158 [ 0.26314757  0.73685243]\n",
      "159 [ 0.78341996  0.21658004]\n",
      "160 [ 0.64508081  0.35491919]\n",
      "161 [ 0.29821818  0.70178182]\n",
      "162 [ 0.70290911  0.29709089]\n",
      "163 [ 0.93628799  0.06371201]\n",
      "164 [ 0.80122977  0.19877023]\n",
      "165 [ 0.20441364  0.79558636]\n",
      "166 [ 0.91423794  0.08576206]\n",
      "167 [ 0.71446947  0.28553053]\n",
      "168 [ 0.2231295  0.7768705]\n",
      "169 [ 0.38443216  0.61556784]\n",
      "170 [ 0.33773335  0.66226665]\n",
      "171 [ 0.7711325  0.2288675]\n",
      "172 [ 0.56270426  0.43729574]\n",
      "173 [ 0.50215312  0.49784688]\n",
      "174 [ 0.33083969  0.66916031]\n",
      "175 [ 0.90969684  0.09030316]\n",
      "176 [ 0.55805916  0.44194084]\n",
      "177 [ 0.7231318  0.2768682]\n",
      "178 [ 0.71897817  0.28102183]\n",
      "179 [ 0.78696849  0.21303151]\n",
      "180 [ 0.46474198  0.53525802]\n",
      "181 [ 0.47866646  0.52133354]\n",
      "182 [ 0.60107063  0.39892937]\n",
      "183 [ 0.48231391  0.51768609]\n",
      "184 [ 0.49864561  0.50135439]\n",
      "185 [ 0.87345673  0.12654327]\n",
      "186 [ 0.92462924  0.07537076]\n",
      "187 [ 0.80195287  0.19804713]\n",
      "188 [ 0.23050436  0.76949564]\n",
      "189 [ 0.57610366  0.42389634]\n",
      "190 [ 0.81545429  0.18454571]\n",
      "191 [ 0.85833473  0.14166527]\n",
      "192 [ 0.25621866  0.74378134]\n",
      "193 [ 0.70406234  0.29593766]\n",
      "194 [ 0.90635701  0.09364299]\n",
      "195 [ 0.90490641  0.09509359]\n",
      "196 [ 0.86166322  0.13833678]\n",
      "197 [ 0.81153438  0.18846562]\n",
      "198 [ 0.71265855  0.28734145]\n",
      "199 [ 0.27301033  0.72698967]\n",
      "200 [ 0.78737002  0.21262998]\n",
      "201 [ 0.86859157  0.13140843]\n",
      "202 [ 0.6616011  0.3383989]\n",
      "203 [ 0.6028733  0.3971267]\n",
      "204 [ 0.45665035  0.54334965]\n",
      "205 [ 0.8798954  0.1201046]\n",
      "206 [ 0.81211685  0.18788315]\n",
      "207 [ 0.80757732  0.19242268]\n",
      "208 [ 0.10370218  0.89629782]\n",
      "209 [ 0.50861782  0.49138218]\n",
      "210 [ 0.67331296  0.32668704]\n",
      "211 [ 0.77898602  0.22101398]\n",
      "212 [ 0.74966631  0.25033369]\n",
      "213 [ 0.82916082  0.17083918]\n",
      "214 [ 0.40354445  0.59645555]\n",
      "215 [ 0.79486135  0.20513865]\n",
      "216 [ 0.22085102  0.77914898]\n",
      "217 [ 0.6704761  0.3295239]\n",
      "218 [ 0.69746621  0.30253379]\n",
      "219 [ 0.15277127  0.84722873]\n",
      "220 [ 0.40021964  0.59978036]\n",
      "221 [ 0.86400748  0.13599252]\n",
      "222 [ 0.81006609  0.18993391]\n",
      "223 [ 0.80560807  0.19439193]\n",
      "224 [ 0.82541014  0.17458986]\n",
      "225 [ 0.49426504  0.50573496]\n",
      "226 [ 0.78360062  0.21639938]\n",
      "227 [ 0.67967497  0.32032503]\n",
      "228 [ 0.72784811  0.27215189]\n",
      "229 [ 0.73431497  0.26568503]\n",
      "230 [ 0.88296013  0.11703987]\n",
      "231 [ 0.89250237  0.10749763]\n",
      "232 [ 0.66550238  0.33449762]\n",
      "233 [ 0.47818398  0.52181602]\n",
      "234 [ 0.57474631  0.42525369]\n",
      "235 [ 0.31174518  0.68825482]\n",
      "236 [ 0.81558424  0.18441576]\n",
      "237 [ 0.74488634  0.25511366]\n",
      "238 [ 0.6055395  0.3944605]\n",
      "239 [ 0.58964322  0.41035678]\n",
      "240 [ 0.83202103  0.16797897]\n",
      "241 [ 0.89264062  0.10735938]\n",
      "242 [ 0.46585401  0.53414599]\n",
      "243 [ 0.79672179  0.20327821]\n",
      "244 [ 0.70416932  0.29583068]\n",
      "245 [ 0.76258097  0.23741903]\n",
      "246 [ 0.2564184  0.7435816]\n",
      "247 [ 0.69843255  0.30156745]\n",
      "248 [ 0.63280495  0.36719505]\n",
      "249 [ 0.74504888  0.25495112]\n",
      "250 [ 0.81680696  0.18319304]\n",
      "251 [ 0.84180718  0.15819282]\n",
      "252 [ 0.30974892  0.69025108]\n",
      "253 [ 0.82163817  0.17836183]\n",
      "254 [ 0.85974941  0.14025059]\n",
      "255 [ 0.2623341  0.7376659]\n",
      "256 [ 0.80746102  0.19253898]\n",
      "257 [ 0.53961845  0.46038155]\n",
      "258 [ 0.84478226  0.15521774]\n",
      "259 [ 0.84446432  0.15553568]\n",
      "260 [ 0.50127116  0.49872884]\n",
      "261 [ 0.70583226  0.29416774]\n",
      "262 [ 0.82776439  0.17223561]\n",
      "263 [ 0.90475795  0.09524205]\n",
      "264 [ 0.76056261  0.23943739]\n",
      "265 [ 0.82736022  0.17263978]\n",
      "266 [ 0.42424719  0.57575281]\n",
      "267 [ 0.7005948  0.2994052]\n",
      "268 [ 0.91979654  0.08020346]\n",
      "269 [ 0.75845388  0.24154612]\n",
      "270 [ 0.86581957  0.13418043]\n",
      "271 [ 0.74878761  0.25121239]\n",
      "272 [ 0.21390751  0.78609249]\n",
      "273 [ 0.3203098  0.6796902]\n",
      "274 [ 0.65012715  0.34987285]\n",
      "275 [ 0.83561113  0.16438887]\n",
      "276 [ 0.85382501  0.14617499]\n",
      "277 [ 0.46018717  0.53981283]\n",
      "278 [ 0.8062279  0.1937721]\n",
      "279 [ 0.66680796  0.33319204]\n",
      "280 [ 0.41972749  0.58027251]\n",
      "281 [ 0.42811779  0.57188221]\n",
      "282 [ 0.18948275  0.81051725]\n",
      "283 [ 0.20893684  0.79106316]\n",
      "284 [ 0.86647086  0.13352914]\n",
      "285 [ 0.66594425  0.33405575]\n",
      "286 [ 0.19756109  0.80243891]\n",
      "287 [ 0.35946368  0.64053632]\n",
      "288 [ 0.91896795  0.08103205]\n",
      "289 [ 0.26040624  0.73959376]\n",
      "290 [ 0.82377764  0.17622236]\n",
      "291 [ 0.63884536  0.36115464]\n",
      "292 [ 0.45687051  0.54312949]\n",
      "293 [ 0.76648518  0.23351482]\n",
      "294 [ 0.72802136  0.27197864]\n",
      "295 [ 0.79162582  0.20837418]\n",
      "296 [ 0.86406619  0.13593381]\n",
      "297 [ 0.47577506  0.52422494]\n",
      "298 [ 0.76998792  0.23001208]\n",
      "299 [ 0.68256387  0.31743613]\n",
      "300 [ 0.66967402  0.33032598]\n",
      "301 [ 0.40100391  0.59899609]\n",
      "302 [ 0.18028542  0.81971458]\n",
      "303 [ 0.91055131  0.08944869]\n",
      "304 [ 0.88815853  0.11184147]\n",
      "305 [ 0.96506353  0.03493647]\n",
      "306 [ 0.74180479  0.25819521]\n",
      "307 [ 0.69367491  0.30632509]\n",
      "\n",
      "\n",
      " The Predicted Class is :\n",
      "\n",
      "\n",
      "[0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 0 1 1 1 1 0 1 1\n",
      " 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 1 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 1 1 0 1 0 0 1 0 0 0\n",
      " 0 1 0 0 0 1 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "print(X_test.shape)\n",
    "print('\\n\\n The probabilities to belong to a Class:\\n\\n')\n",
    "y_pred_prob = logreg.predict_proba(X_test)\n",
    "for i in range(len(y_pred_prob)):\n",
    "    print(str(i)+\" \"+str(y_pred_prob[i]))\n",
    "print('\\n\\n The Predicted Class is :\\n\\n')\n",
    "y_pred_prob=y_pred_prob[:,1]\n",
    "print(logreg.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 1 1 0 1 1\n",
      " 1 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 1 1 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 0 1 1\n",
      " 0 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 1 1 0 0 0 0 1 0 1 0\n",
      " 0 1 1 0 0 1 1 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkWz/Dz2d3nO6y2pOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18710a9cc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "print(y_test)\n",
    "fpr,tpr,thresholds= roc_curve(y_test,y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr,tpr,label='Logistic Regression')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at your ROC curve, you may have noticed that the y-axis (True positive rate) is also known as recall. Indeed, in addition to the ROC curve, there are other ways to visually evaluate model performance. One such way is the precision-recall curve, which is generated by plotting the precision and recall for different thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we  have a binary classifier that in fact is just randomly making guesses. It would be correct approximately 50% of the time, and the resulting ROC curve would be a diagonal line in which the True Positive Rate and False Positive Rate are always equal. The Area under this ROC curve would be 0.5.\n",
    "\n",
    "If the AUC is greater than 0.5, the model is better than random guessing. Always a good sign! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8086331620026652\n",
      "AUC scores computed using 5-fold cross-validation: [ 0.79518519  0.79518519  0.84277778  0.87169811  0.85169811]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob =logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute and print AUC score\n",
    "print(\"AUC: {}\".format(roc_auc_score(y_test,y_pred_prob)))\n",
    "\n",
    "# Compute cross-validated AUC scores: cv_auc\n",
    "cv_auc =cross_val_score(logreg,X,y,cv=5,scoring='roc_auc')\n",
    "\n",
    "# Print list of AUC scores\n",
    "print(\"AUC scores computed using 5-fold cross-validation: {}\".format(cv_auc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tune the n_neighbors parameter of the KNeighborsClassifier() using GridSearchCV on the voting dataset. We will now practice this ourself, but by using logistic regression on the diabetes dataset instead! \n",
    "\n",
    "Like the alpha parameter of lasso and ridge regularization that we saw earlier, logistic regression also has a regularization parameter: C. C controls the inverse of the regularization strength, and this is what we will tune in this exercise. A large C can lead to an overfit model, while a small C can lead to an underfit model.\n",
    "\n",
    "Our job is to use GridSearchCV and logistic regression to find the optimal C in this hyperparameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Value of C-space is:\n",
      "\n",
      "\n",
      "[  1.00000000e-05   8.48342898e-05   7.19685673e-04   6.10540230e-03\n",
      "   5.17947468e-02   4.39397056e-01   3.72759372e+00   3.16227766e+01\n",
      "   2.68269580e+02   2.27584593e+03   1.93069773e+04   1.63789371e+05\n",
      "   1.38949549e+06   1.17876863e+07   1.00000000e+08]\n",
      "\n",
      "\n",
      "\n",
      "GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'C': array([  1.00000e-05,   8.48343e-05,   7.19686e-04,   6.10540e-03,\n",
      "         5.17947e-02,   4.39397e-01,   3.72759e+00,   3.16228e+01,\n",
      "         2.68270e+02,   2.27585e+03,   1.93070e+04,   1.63789e+05,\n",
      "         1.38950e+06,   1.17877e+07,   1.00000e+08])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "\n",
      "\n",
      " The Best Parameters Are :\n",
      "\n",
      "\n",
      "Tuned Logistic Regression Parameters: {'C': 268.26957952797272}\n",
      "Best score is 0.7708333333333334\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Setup the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)    #takes 15 values between e^(-5) to e^(+8)\n",
    "param_grid = {'C':c_space}\n",
    "print(\"The Value of C-space is:\\n\\n\")\n",
    "print(c_space)\n",
    "print('\\n\\n')\n",
    "# Instantiate a logistic regression classifier: logreg\n",
    "logreg =LogisticRegression()\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg,param_grid, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "logreg_cv.fit(X,y)\n",
    "print(logreg_cv)\n",
    "# Print the tuned parameters and score\n",
    "print('\\n\\n The Best Parameters Are :\\n\\n')\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) \n",
    "print(\"Best score is {}\".format(logreg_cv.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV can be computationally expensive, especially if we are searching over a large hyperparameter space and dealing with multiple hyperparameters. A solution to this is to use RandomizedSearchCV, in which not all hyperparameter values are tried out. Instead, a fixed number of hyperparameter settings is sampled from specified probability distributions. \n",
    "\n",
    "Here,we'll also be introduced to a new model: the Decision Tree. Just like k-NN, linear regression, and logistic regression, decision trees in scikit-learn have .fit() and .predict() methods that we can use in exactly the same way as before. Decision trees have many parameters that can be tuned, such as max_features, max_depth, and min_samples_leaf: This makes it an ideal use case for RandomizedSearchCV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 7, 'min_samples_leaf': 7}\n",
      "Best score is 0.7434895833333334\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, 9),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree =DecisionTreeClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv =RandomizedSearchCV(tree,param_dist, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "\n",
    "tree_cv.fit(X,y)\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note that RandomizedSearchCV will never outperform GridSearchCV. Instead, it is valuable because it saves on computation time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# HOLD OUT SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of Hold Out is to tune the model's hyperparameters on the training set, and then evaluate its performance on the hold-out set which it has never seen before.\n",
    "\n",
    "In addition to C, logistic regression has a 'penalty' hyperparameter which specifies whether to use 'l1' or 'l2' regularization. In this exercise we will  create a hold-out set, tune the 'C' and 'penalty' hyperparameters of a logistic regression classifier using GridSearchCV on the training set, and then evaluate its performance against the hold-out set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameter: {'C': 31.622776601683793, 'penalty': 'l1'}\n",
      "Tuned Logistic Regression Accuracy: 0.7717391304347826\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C':c_space,'penalty': ['l1', 'l2']}\n",
    "\n",
    "# Instantiate the logistic regression classifier: logreg\n",
    "logreg =LogisticRegression()\n",
    "\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test =train_test_split(X,y,test_size=0.4,random_state=42)\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv =GridSearchCV(logreg,param_grid,cv=5)\n",
    "\n",
    "# Fit it to the training data\n",
    "logreg_cv.fit(X_train,y_train)\n",
    "\n",
    "# Print the optimal parameters and best score\n",
    "print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
    "print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso used the L1 penalty to regularize, while ridge used the L2 penalty. There is another type of regularized regression known as the elastic net. In elastic net regularization, the penalty term is a linear combination of the L1 and L2 penalties:\n",
    "\n",
    "                        aâˆ—L1+bâˆ—L2\n",
    "\n",
    "In scikit-learn, this term is represented by the 'l1_ratio' parameter: An 'l1_ratio' of 1 corresponds to an L1\n",
    "penalty, and anything lower is a combination of L1 and L2.\n",
    "\n",
    "Here,we will GridSearchCV to tune the 'l1_ratio' of an elastic net model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Subham\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:470: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\Subham\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Subham\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:470: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\Subham\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Subham\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:470: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\Subham\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Subham\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:470: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\Subham\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Subham\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:470: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\Subham\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned ElasticNet l1 ratio: {'l1_ratio': 0.034482758620689655}\n",
      "Tuned ElasticNet R squared: 0.25979075135841456\n",
      "Tuned ElasticNet MSE: 0.1639534147037548\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test =train_test_split(X,y,test_size=0.4,random_state=42)\n",
    "\n",
    "# Create the hyperparameter grid\n",
    "l1_space = np.linspace(0, 1, 30)\n",
    "param_grid = {'l1_ratio':l1_space}\n",
    "\n",
    "# Instantiate the ElasticNet regressor: elastic_net\n",
    "elastic_net = ElasticNet()\n",
    "\n",
    "# Setup the GridSearchCV object: gm_cv\n",
    "gm_cv = GridSearchCV(elastic_net,param_grid,cv=5)\n",
    "\n",
    "# Fit it to the training data\n",
    "gm_cv.fit(X_train,y_train)\n",
    "\n",
    "# Predict on the test set and compute metrics\n",
    "y_pred = gm_cv.predict(X_test)\n",
    "r2 = gm_cv.score(X_test, y_test)\n",
    "mse = (mean_squared_error(y_test,y_pred))\n",
    "print(\"Tuned ElasticNet l1 ratio: {}\".format(gm_cv.best_params_))\n",
    "print(\"Tuned ElasticNet R squared: {}\".format(r2))\n",
    "print(\"Tuned ElasticNet MSE: {}\".format(mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
